

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Credibility User Guide &mdash; Model Validation Toolkit 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/logo.svg"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Thresholding User Guide" href="thresholding_user_guide.html" />
    <link rel="prev" title="Supervisor User Guide" href="supervisor_user_guide.html" />
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2BGSHYDJP8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2BGSHYDJP8');
</script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Model Validation Toolkit
          

          
            
            <img src="_static/logo.svg" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html">About</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guides</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="supervisor_user_guide.html">Supervisor User Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Credibility User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#motivation">Motivation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how">How?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#beta-distributions">Beta Distributions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#probability-of-low-performance">Probability of Low Performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="#credible-intervals">Credible Intervals</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#common-metrics">Common Metrics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#roc-auc">ROC AUC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="thresholding_user_guide.html">Thresholding User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="interprenet_user_guide.html">Interprenet User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="sobol_user_guide.html">Sobol User Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">Divergence Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/divergence/Airlines.html">Airlines Dataset: Divergence Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/divergence/DivergenceFunctions.html">Notes on Using Divergence Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/divergence/CategoricalColumns.html">Handling Categorical Data</a></li>
</ul>
<p class="caption"><span class="caption-text">Credibility Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/credibility/Credibility.html">Assessing Credibility From Sample Size</a></li>
</ul>
<p class="caption"><span class="caption-text">Thresholding Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/thresholding/Thresholding.html">Introduction to Adaptive Thresholding</a></li>
</ul>
<p class="caption"><span class="caption-text">Interprenet Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/interprenet/Interprenet.html">Introduction to Interprenet</a></li>
</ul>
<p class="caption"><span class="caption-text">Bias and Metrics Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/metrics/CounteringSampleBias.html">Countering Sample Bias</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="supervisor.html">supervisor</a></li>
<li class="toctree-l1"><a class="reference internal" href="credibility.html">credibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="thresholding.html">thresholding</a></li>
<li class="toctree-l1"><a class="reference internal" href="interprenet.html">interprenet</a></li>
<li class="toctree-l1"><a class="reference internal" href="sobol.html">sobol</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">metrics</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Model Validation Toolkit</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Credibility User Guide</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/credibility_user_guide.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="credibility-user-guide">
<h1>Credibility User Guide<a class="headerlink" href="#credibility-user-guide" title="Permalink to this headline">¶</a></h1>
<div class="section" id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Let’s say we are training a model for medical diagnoses. Missing false negatives
is important and we have a hard requirement that a model’s recall (proportion
of positive instances identified) must not fall below 70%. If someone validates
a model and reports a recall of 80%, are we clear? Well, maybe. It turns out
this data scientist had a validation set with 5 positive instances. The model
correctly identified 4 of them, giving it a recall of 80%. Would you trust
that? Of course not! You say that a larger sample size is needed. “How many do we
need?” they ask. This module will help answer that question.</p>
<div class="section" id="how">
<h3>How?<a class="headerlink" href="#how" title="Permalink to this headline">¶</a></h3>
<p>There’s two schools of thought for this problem. The <a class="reference external" href="https://en.wikipedia.org/wiki/Frequentist_probability">frequentist</a> and the
<a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_probability">Bayesian</a> approaches.
In practice they tend to give similar results. Going back to our 5 sample
validation set, the frequentist would be concerned with how much our recall
would be expected to vary from one 5 sample hold out set to another. They would
want the hold out set to be large enough that you would not expect much change
in the estimated recall from one hold out set to another. The Bayesian approach
seeks to directly identify the probability that the recall would be lower than
70% if the validation set were infinitely large. We believe this is a better
representation of the problem at hand, and designed the library around this
Bayesian approach.</p>
</div>
</div>
<div class="section" id="beta-distributions">
<h2>Beta Distributions<a class="headerlink" href="#beta-distributions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="probability-of-low-performance">
<h3>Probability of Low Performance<a class="headerlink" href="#probability-of-low-performance" title="Permalink to this headline">¶</a></h3>
<p>If you flip a coin 100 times, and it comes up heads 99 times, would you suspect
a biased coin? Probably. What about if you flipped it 5 times and saw 4 heads.
This is much less strange. Determining the bias of a coin embodies the core
principles behind determining whether many performance metrics are unacceptably
low.</p>
<p>If the coin <em>is</em> biased, how biased is it? In general, we’d say there’s some
probability distribution over all possible biases. We would generally use a
<a class="reference external" href="https://en.wikipedia.org/wiki/Beta_distribution">beta distribution</a> to
model this distribution for good reasons. This distribution has two free
parameters: the number of heads and the number of tails. However, we generally
offset both of those numbers by 1 so the distribution for observed flips is
<span class="math notranslate nohighlight">\(B(1, 1)\)</span> (with <span class="math notranslate nohighlight">\(B\)</span> representing our beta distribution as a
function of heads and tails plus respective offsets), which as it turns out is
exactly a uniform distribution over all possible biases. In this sense, we can
express total uncertainty before taking measurements. The beta distribution
becomes more concentrated around the empirical proportion of heads as you take
more and more measurements. If, we were reasonably certain of a 60% bias, we
might offset the number of heads with a 6 and the number of tails with a 4.
Then we would start to expect an unbiased coin after observing 2 tails. This
offset is called the <em>prior</em> in Bayesian inference, and represents our
understanding before making any observations.</p>
<div class="math notranslate nohighlight">
\[B(\alpha, \beta)\]</div>
<div class="align-center figure" id="id2">
<a class="reference internal image-reference" href="_images/Beta_distribution_pdf.svg"><img alt="alternate text" height="400px" src="_images/Beta_distribution_pdf.svg" width="800px" /></a>
<p class="caption"><span class="caption-text">Beta distribution for different <span class="math notranslate nohighlight">\(alpha\)</span> (for heads plus offset) and
<span class="math notranslate nohighlight">\(\beta\)</span> (tails plus offset).</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<p>We integrate the area under <span class="math notranslate nohighlight">\(B(\alpha,\beta)\)</span> from 0 to
<span class="math notranslate nohighlight">\(p\)</span> to determine the probability that a coin’s bias is less
than <span class="math notranslate nohighlight">\(p\)</span>. This is effectively how <a class="reference internal" href="credibility.html#mvtk.credibility.prob_below" title="mvtk.credibility.prob_below"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prob_below()</span></code></a> works.</p>
</div>
<div class="section" id="credible-intervals">
<h3>Credible Intervals<a class="headerlink" href="#credible-intervals" title="Permalink to this headline">¶</a></h3>
<p>Sometimes you just want a general sense of uncertainty for your sample
estimates. We use <a class="reference internal" href="credibility.html#mvtk.credibility.credible_interval" title="mvtk.credibility.credible_interval"><code class="xref py py-meth docutils literal notranslate"><span class="pre">credible_interval()</span></code></a> to compute a <a class="reference external" href="https://en.wikipedia.org/wiki/Credible_interval">credible interval</a>. This will give you the
smallest interval for which there is a <cite>credibility</cite> (kwarg argument that
defaults to <span class="math notranslate nohighlight">\(0.5\)</span>) chance of the bias being within that region. It will
return a lower bound no less than <span class="math notranslate nohighlight">\(0\)</span> and an upper bound no greater than <span class="math notranslate nohighlight">\(1\)</span>.
This is subtly different from frequentist <a class="reference external" href="https://en.wikipedia.org/wiki/Confidence_interval">confidence intervals</a>. In our 5 sample
example, the latter reports an interval that is expected to contain <cite>p</cite> (often
chosen to be 95%) all such 5 sample estimates of the mean.</p>
</div>
</div>
<div class="section" id="common-metrics">
<h2>Common Metrics<a class="headerlink" href="#common-metrics" title="Permalink to this headline">¶</a></h2>
<p>Many performance metrics used for binary
classification follow the same mechanics as the
analysis above. This following is not an exhaustive
list of performance metrics that can be readily
translated into a biased coin scenario in which we
wish to determine heads / (heads + tails).</p>
<ul class="simple">
<li><p>Precision: true positive / (true positive + false positive)</p></li>
<li><p>Recall: true positive / (true positive + false negative)</p></li>
<li><p>Accuracy: correctly identified / (correctly identified + incorrectly identified)</p></li>
</ul>
<div class="section" id="roc-auc">
<h3>ROC AUC<a class="headerlink" href="#roc-auc" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC AUC</a>
is an extremely useful measure for binary classification. Like many
other measures of performance for binary classification, it can be
expressed as a proportion of outcomes. However,
unlike other measures of performance, it does not
make use of a threshold. This ultimately makes it a
ranking metric, as it characterizes the degree to
which positive instances are scored higher than
negative instances. However, like other metrics, it
can be expressed as an empirical measure of a
proportion. Specifically, ROC AUC is the proportion
of pairs of positive and negative examples such
that the positive example is scored higher than the
negative one. This can be expressed as</p>
<div class="math notranslate nohighlight">
\[\frac{1}{NM}\sum\limits_{n,m}^{N,M} \mathrm{score}(\mathrm{Positive}_n) &gt; \mathrm{score}(\mathrm{Negative}_m)\]</div>
<p>However, computing the area under the receiver
operating characteristic is a more computationally
efficient means of computing the same quantity.
<a class="reference internal" href="credibility.html#mvtk.credibility.roc_auc_preprocess" title="mvtk.credibility.roc_auc_preprocess"><code class="xref py py-meth docutils literal notranslate"><span class="pre">roc_auc_preprocess()</span></code></a> will convert a positive and negative
sample count to an associated count of correctly and incorrectly
ranked pairs of positive and negative instances using the ROC AUC
score. This pair of numbers can be used as arguments for
<a class="reference internal" href="credibility.html#mvtk.credibility.prob_below" title="mvtk.credibility.prob_below"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prob_below()</span></code></a> and <a class="reference internal" href="credibility.html#mvtk.credibility.credible_interval" title="mvtk.credibility.credible_interval"><code class="xref py py-meth docutils literal notranslate"><span class="pre">credible_interval()</span></code></a>.</p>
<div class="topic">
<p class="topic-title">Tutorials:</p>
<ul class="simple">
<li><p><a class="reference internal" href="notebooks/credibility/Credibility.html"><span class="doc">Credibility</span></a></p></li>
</ul>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="thresholding_user_guide.html" class="btn btn-neutral float-right" title="Thresholding User Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="supervisor_user_guide.html" class="btn btn-neutral float-left" title="Supervisor User Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Model Validation Toolkit Team.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>